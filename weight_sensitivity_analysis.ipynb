{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weight_sensitivity_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdG0zxAPPw2gKkIKi/egWk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sxg4060/Weight-Sensitivity-Analysis/blob/main/weight_sensitivity_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Pgco8q13sI"
      },
      "source": [
        "pip install -q pyyaml h5py # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoLEQgnv143d"
      },
      "source": [
        "import logging\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import h5py\n",
        "import re\n",
        "import sys\n",
        "import random\n",
        "from struct import *\n",
        "from keras import backend as K\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.conv_utils import convert_kernel\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Sequential\n",
        "from numpy import savetxt\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D\n",
        "from keras import activations\n",
        "from keras.utils.conv_utils import convert_kernel\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rGQ2Wnk16Oa"
      },
      "source": [
        "import struct\n",
        "\n",
        "def float_to_bin(num):\n",
        "    return format(struct.unpack('!I', struct.pack('!f', num))[0], '032b')\n",
        "\n",
        "def bin_to_float(binary):\n",
        "    return struct.unpack('!f',struct.pack('!I', int(binary, 2)))[0]\n",
        "\n",
        "##bit flip function-flips bit in float value based on position\n",
        "def weight_bit_flip(weight, flip_position):\n",
        "    #add 2 to flip position-reflect actual position in number\n",
        "    #flip_position = flip_position + 2\n",
        "    #convert weight to hex then binary\n",
        "    bin_weight = float_to_bin(weight)\n",
        "    #bin_weight= bin(int.from_bytes(pack('f', weight), byteorder=sys.byteorder))\n",
        "    print(\"input bits: \" + str(bin_weight))\n",
        "    bin_weight = list(bin_weight)\n",
        "    \n",
        "          \n",
        "       \n",
        "    #check to make sure flip is valid position\n",
        "    if flip_position > (len(bin_weight)):\n",
        "        print(\"invalid position for bit flip\")\n",
        "        return\n",
        "\n",
        "    #flip bit-case for flip at end, middle\n",
        "    bin_weight_flip=bin_weight\n",
        "    if bin_weight[flip_position] == str(0):\n",
        "        print(flip_position)\n",
        "        bin_weight_flip[flip_position] ='1' \n",
        "    else:\n",
        "        bin_weight_flip[flip_position] ='0'\n",
        "    \n",
        "    #join list back into string\n",
        "    bin_weight_flip=\"\".join(bin_weight_flip)\n",
        "    \n",
        "    #convert binary weight back into float-convert to binary to hex to float\n",
        "    print(\"output bits: \"+bin_weight_flip)\n",
        "    return bin_weight_flip\n",
        "    #byte_weight_flip=int(bin_weight_flip,2).to_bytes(4, byteorder=sys.byteorder)\n",
        "    #weight_flip=unpack('f', byte_weight_flip)\n",
        "    #print(weight_flip[0])\n",
        "    #return round(weight_flip[0],10)\n",
        "\n",
        "def ieee_parser(ieee_binary):\n",
        "    sign = int(ieee_binary[0])\n",
        "    if sign == 1:\n",
        "      sign = -1\n",
        "    if sign == 0:\n",
        "      sign = 1\n",
        "    #print(\"Sign = \", sign)\n",
        "    exponent = int(ieee_binary[1:9],2)\n",
        "    #print(\"Exponent = \", exponent)\n",
        "    mantissa = 1\n",
        "    for i in range(1,24):\n",
        "      #print(int(ieee_binary[i+8]))\n",
        "      temp1 = (int(ieee_binary[i+8]))*(2**-i)\n",
        "      #print(temp1)\n",
        "      mantissa = mantissa + temp1\n",
        "    #print(\"Mantissa = \", mantissa)\n",
        "    value = sign * ((2)**(exponent-127)) * (mantissa) \n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ7wISxz199n"
      },
      "source": [
        "op = weight_bit_flip(0.123213,0)\n",
        "print(ieee_parser(op))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9-xkPPU1-e4"
      },
      "source": [
        "# Load MNIST dataset \n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn-nPIGX2ACa"
      },
      "source": [
        "def make_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, input_shape=(784,)))\n",
        "  model.add(Activation(activations.softmax, input_shape=(10,)))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "K.set_floatx('float32')\n",
        "model = make_model()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=1,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feoCR6HD2Crc"
      },
      "source": [
        "min_wt = x_test.min()\n",
        "\n",
        "max_wt = x_test.max()\n",
        "\n",
        "int_bits = int(np.ceil(np.log2(max(abs(min_wt),abs(max_wt)))))\n",
        "\n",
        "frac_bits = 3-int_bits\n",
        "\n",
        "quant_weight = np.round((x_test)*(2**frac_bits))\n",
        "\n",
        "recovered_weight = quant_weight/(2**frac_bits)\n",
        "\n",
        "min_wt_y = y_test.min()\n",
        "\n",
        "max_wt_y = y_test.max()\n",
        "\n",
        "int_bits_y = int(np.ceil(np.log2(max(abs(min_wt_y),abs(max_wt_y)))))\n",
        "\n",
        "frac_bits_y = 3-int_bits_y\n",
        "\n",
        "quant_weight_y = np.round((y_test)*(2**frac_bits_y))\n",
        "\n",
        "recovered_weight_y = quant_weight_y/(2**frac_bits_y)\n",
        "print('Original weights: ', model.get_weights())\n",
        "print('Quantized weights:', quant_weight[0])\n",
        "print('Recovered weights: ', recovered_weight[0])\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# save model and architecture to single file\n",
        "model.save(\"model.h5\")\n",
        "model.save_weights(\"trained_weights.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "print(\"====Model Weights====\")\n",
        "print(model.get_weights()[0])\n",
        "print(\"====Model Predictions===\")\n",
        "print(model.predict(x_test, batch_size=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLidLDzY2E1F"
      },
      "source": [
        "# Layer Sensitivity Analysis\n",
        "\n",
        "amount = 0.1\n",
        "# Create new model_prime with trained weights\n",
        "model.load_weights('trained_weights.h5')\n",
        "layer_i = model.layers[0]\n",
        "#print(layer_i.get_weights()[0])\n",
        "\n",
        "# Variables to traverse array\n",
        "\n",
        "a = layer_i.get_weights()[0] * 1\n",
        "b = layer_i.get_weights()[1] * 1\n",
        "\n",
        "model.layers[0].set_weights([a,b])\n",
        "#print(model.layers[0].get_weights()[0])\n",
        "\n",
        "\n",
        "model.save_weights('modified_weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujBT8BSv2FRS"
      },
      "source": [
        "# RH ALL\n",
        "orig_array=model.layers[0].get_weights()\n",
        "orig_weight=orig_array[0][0, 0]\n",
        "\n",
        "##enter loop to modify number with bit flip\n",
        "##pull initial value for weight\n",
        "orig_array=model.layers[0].get_weights()\n",
        "orig_weight=orig_array[0][0,0]\n",
        "##initial weight array\n",
        "bit_flip_array=orig_array\n",
        "x_array = []\n",
        "y_array = []\n",
        "acc_array = []\n",
        "for x in range(783, 0, -1):\n",
        "  for y in range(9, 0, -1):\n",
        "      print(\"Weight to be modified = \" + str(orig_array[0][x,y]))\n",
        "      bit_flip_array[0][x,y] = ieee_parser(weight_bit_flip(orig_array[0][x,y], 0))\n",
        "      print(\"new weight: \" +str(bit_flip_array[0][x,y]))\n",
        "      model.layers[0].set_weights(bit_flip_array)\n",
        "      model.save_weights('modified_weight.h5')\n",
        "      load_model = make_model()\n",
        "      load_model.load_weights('modified_weight.h5')\n",
        "      updated_score = load_model.evaluate(x_test,  y_test, verbose=2)\n",
        "      print(\"%s: %.2f%%\" % (load_model.metrics_names[1], updated_score[1]*100))\n",
        "      print('Test loss:', updated_score[0])\n",
        "      print('Test accuracy:', updated_score[1])\n",
        "      x_array.append(x)\n",
        "      y_array.append(y)\n",
        "      acc_array.append(updated_score[1])\n",
        "      bit_flip_array[0][x,y] = -1 * orig_array[0][x,y]\n",
        "      model.layers[0].set_weights(bit_flip_array)\n",
        "      model.save_weights('modified_weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYWplgvU2Igd"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "acc32_array = acc_array\n",
        "x32_array = x_array\n",
        "y32_array = y_array\n",
        "# Data for a three-dimensional line\n",
        "zline = acc32_array\n",
        "xline = x32_array\n",
        "yline = y32_array\n",
        "ax.scatter3D(xline, yline, zline, c=zline, cmap='Greens');\n",
        "print(acc_array)\n",
        "print(max(acc_array))\n",
        "print(min(acc_array))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}